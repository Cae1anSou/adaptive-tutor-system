#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®æ—¶å­¦ä¹ è¿›åº¦åˆ†æå™¨
è§£å†³å½“å‰èšç±»ç³»ç»Ÿéœ€è¦å¤§é‡æ•°æ®çš„é—®é¢˜
"""

import sys
import os
import re
import json
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, UTC
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.user_state_service import UserStateService, StudentProfile


class RealTimeProgressAnalyzer:
    """å®æ—¶å­¦ä¹ è¿›åº¦åˆ†æå™¨"""
    
    def __init__(self):
        # å…³é”®è¯è¯å…¸
        self.DONE_KEYWORDS = {
            "complete", "completed", "finish", "finished", "pass", "passed", 
            "accept", "accepted", "solved", "resolve", "resolved", "fix", "fixed", 
            "merge", "merged", "success", "successfully", "ok", "ac", "working", "works"
        }
        
        self.STUCK_KEYWORDS = {
            "error", "errors", "failed", "fail", "stuck", "bug", "exception", 
            "timeout", "timed out", "crash", "cannot", "not working", "confused", 
            "don't understand", "help", "lost", "difficult", "hard", "problem"
        }
        
        self.CONFIDENCE_KEYWORDS = {
            "confident", "understand", "clear", "got it", "makes sense", 
            "easy", "simple", "straightforward"
        }
        
        self.FRUSTRATION_KEYWORDS = {
            "frustrated", "frustrating", "annoying", "give up", "quit", 
            "impossible", "hate", "terrible", "awful"
        }

    def analyze_real_time_progress(self, 
                                   participant_id: str, 
                                   conversation_history: List[Dict[str, str]],
                                   current_message: str = None) -> Dict[str, Any]:
        """
        å®æ—¶åˆ†æå­¦ä¹ è¿›åº¦ï¼ˆæ— éœ€ç­‰å¾…å¤§é‡æ•°æ®ï¼‰
        
        Args:
            participant_id: å‚ä¸è€…ID
            conversation_history: å¯¹è¯å†å²
            current_message: å½“å‰æ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            å®æ—¶è¿›åº¦åˆ†æç»“æœ
        """
        # æå–ç”¨æˆ·æ¶ˆæ¯
        user_messages = [msg['content'] for msg in conversation_history if msg.get('role') == 'user']
        if current_message:
            user_messages.append(current_message)
        
        if len(user_messages) == 0:
            return self._default_progress_result()
        
        # åˆ†å±‚åˆ†æç­–ç•¥
        if len(user_messages) < 5:
            return self._analyze_early_stage(user_messages, participant_id)
        elif len(user_messages) < 12:
            return self._analyze_mid_stage(user_messages, participant_id)
        else:
            return self._analyze_full_stage(user_messages, participant_id)

    def _analyze_early_stage(self, user_messages: List[str], participant_id: str) -> Dict[str, Any]:
        """æ—©æœŸé˜¶æ®µåˆ†æï¼ˆ1-4æ¡æ¶ˆæ¯ï¼‰"""
        print(f"ğŸŒ± æ—©æœŸé˜¶æ®µåˆ†æ: {len(user_messages)}æ¡æ¶ˆæ¯")
        
        # åŸºäºå…³é”®è¯çš„å¿«é€Ÿåˆ†æ
        done_count = sum(self._count_keywords(msg, self.DONE_KEYWORDS) for msg in user_messages)
        stuck_count = sum(self._count_keywords(msg, self.STUCK_KEYWORDS) for msg in user_messages)
        confidence_count = sum(self._count_keywords(msg, self.CONFIDENCE_KEYWORDS) for msg in user_messages)
        frustration_count = sum(self._count_keywords(msg, self.FRUSTRATION_KEYWORDS) for msg in user_messages)
        
        # æ¶ˆæ¯é•¿åº¦å’Œå¤æ‚åº¦åˆ†æ
        avg_length = np.mean([len(msg) for msg in user_messages])
        
        # ç®€å•çš„è¿›åº¦è¯„ä¼°
        progress_indicators = {
            'done_ratio': done_count / len(user_messages),
            'stuck_ratio': stuck_count / len(user_messages),
            'confidence_ratio': confidence_count / len(user_messages),
            'frustration_ratio': frustration_count / len(user_messages),
            'avg_message_length': avg_length
        }
        
        # æ—©æœŸè¿›åº¦åˆ†æ•°
        progress_score = (
            progress_indicators['done_ratio'] * 0.4 +
            progress_indicators['confidence_ratio'] * 0.3 -
            progress_indicators['stuck_ratio'] * 0.3 -
            progress_indicators['frustration_ratio'] * 0.2
        )
        
        # æ—©æœŸåˆ†ç±»
        if progress_score > 0.2:
            cluster_name = "æ—©æœŸæ­£é¢"
            teaching_strategy = "maintain_momentum"
        elif progress_score < -0.2:
            cluster_name = "æ—©æœŸå›°éš¾"
            teaching_strategy = "provide_support"
        else:
            cluster_name = "æ—©æœŸæ¢ç´¢"
            teaching_strategy = "gentle_guidance"
        
        return {
            'analysis_type': 'early_stage',
            'cluster_name': cluster_name,
            'progress_score': progress_score,
            'confidence': 0.6,  # æ—©æœŸç½®ä¿¡åº¦è¾ƒä½
            'teaching_strategy': teaching_strategy,
            'indicators': progress_indicators,
            'message_count': len(user_messages),
            'stage': 'early'
        }

    def _analyze_mid_stage(self, user_messages: List[str], participant_id: str) -> Dict[str, Any]:
        """ä¸­æœŸé˜¶æ®µåˆ†æï¼ˆ5-11æ¡æ¶ˆæ¯ï¼‰"""
        print(f"ğŸŒ¿ ä¸­æœŸé˜¶æ®µåˆ†æ: {len(user_messages)}æ¡æ¶ˆæ¯")
        
        # æ›´å¤æ‚çš„æ¨¡å¼åˆ†æ
        recent_messages = user_messages[-5:]  # æœ€è¿‘5æ¡
        
        # è®¡ç®—å„ç§æŒ‡æ ‡
        indicators = self._calculate_detailed_indicators(user_messages)
        
        # è¶‹åŠ¿åˆ†æ
        early_score = self._calculate_period_score(user_messages[:len(user_messages)//2])
        recent_score = self._calculate_period_score(recent_messages)
        
        trend = recent_score - early_score
        
        # ä¸­æœŸè¿›åº¦åˆ†æ•°ï¼ˆæ›´å¤æ‚çš„è®¡ç®—ï¼‰
        progress_score = (
            indicators['done_ratio'] * 0.3 +
            indicators['confidence_ratio'] * 0.2 -
            indicators['stuck_ratio'] * 0.3 -
            indicators['repetition_rate'] * 0.2 +
            trend * 0.3  # è¶‹åŠ¿æƒé‡
        )
        
        # ä¸­æœŸåˆ†ç±»
        if progress_score > 0.3:
            cluster_name = "ä¸­æœŸè¿›å±•"
            teaching_strategy = "increase_challenge"
        elif progress_score < -0.3:
            cluster_name = "ä¸­æœŸå›°éš¾"
            teaching_strategy = "provide_scaffolding"
        else:
            cluster_name = "ä¸­æœŸç¨³å®š"
            teaching_strategy = "maintain_pace"
        
        return {
            'analysis_type': 'mid_stage',
            'cluster_name': cluster_name,
            'progress_score': progress_score,
            'confidence': 0.75,  # ä¸­æœŸç½®ä¿¡åº¦æé«˜
            'teaching_strategy': teaching_strategy,
            'indicators': indicators,
            'trend': trend,
            'message_count': len(user_messages),
            'stage': 'mid'
        }

    def _analyze_full_stage(self, user_messages: List[str], participant_id: str) -> Dict[str, Any]:
        """å®Œæ•´é˜¶æ®µåˆ†æï¼ˆâ‰¥12æ¡æ¶ˆæ¯ï¼‰- å¯ä»¥å°è¯•å®Œæ•´èšç±»"""
        print(f"ğŸŒ³ å®Œæ•´é˜¶æ®µåˆ†æ: {len(user_messages)}æ¡æ¶ˆæ¯")
        
        # é¦–å…ˆå°è¯•å®Œæ•´èšç±»
        try:
            from app.services.user_state_service import PROGRESS_CLUSTERING_AVAILABLE, progress_clustering_pipeline
            
            if PROGRESS_CLUSTERING_AVAILABLE:
                print("ğŸ”¬ å°è¯•å®Œæ•´èšç±»åˆ†æ...")
                
                # å¯ç”¨ç»“æ„ç‰¹å¾å‚ä¸èšç±»
                clustering_result = progress_clustering_pipeline(
                    raw_msgs=user_messages,
                    batch_size=min(12, len(user_messages)),
                    overlap=min(4, len(user_messages)//3),
                    model_name="sentence-transformers/all-mpnet-base-v2",
                    pca_dim=min(64, len(user_messages)-1),
                    include_struct_in_clustering=True,  # å¯ç”¨è¡Œä¸ºç‰¹å¾
                    lookback=2,
                    n_init=20,  # å‡å°‘è®¡ç®—é‡
                    max_iter=300,
                    random_state=42,
                    struct_weight=2.0,
                    near_sim_thresh=0.95
                )
                
                # å¦‚æœèšç±»æˆåŠŸï¼Œè¿”å›èšç±»ç»“æœ
                if clustering_result:
                    latest_window_idx = len(clustering_result['windows']) - 1
                    return {
                        'analysis_type': 'full_clustering',
                        'cluster_name': clustering_result['named_labels'][latest_window_idx],
                        'progress_score': float(clustering_result['progress_score'][latest_window_idx]),
                        'confidence': float(clustering_result['sims'][latest_window_idx]),
                        'teaching_strategy': self._get_strategy_from_cluster(clustering_result['named_labels'][latest_window_idx]),
                        'silhouette_score': clustering_result.get('silhouette', 0.0),
                        'total_windows': len(clustering_result['windows']),
                        'message_count': len(user_messages),
                        'stage': 'full'
                    }
        except Exception as e:
            print(f"âš ï¸ å®Œæ•´èšç±»å¤±è´¥ï¼Œå›é€€åˆ°é«˜çº§åˆ†æ: {e}")
        
        # å¦‚æœèšç±»å¤±è´¥ï¼Œä½¿ç”¨é«˜çº§åˆ†æ
        return self._advanced_analysis_fallback(user_messages, participant_id)

    def _advanced_analysis_fallback(self, user_messages: List[str], participant_id: str) -> Dict[str, Any]:
        """é«˜çº§åˆ†æå›é€€æ–¹æ¡ˆ"""
        print("ğŸ”§ ä½¿ç”¨é«˜çº§åˆ†æå›é€€æ–¹æ¡ˆ")
        
        # å¤æ‚çš„æŒ‡æ ‡è®¡ç®—
        indicators = self._calculate_detailed_indicators(user_messages)
        
        # æ—¶é—´çª—å£åˆ†æ
        window_size = 5
        windows = [user_messages[i:i+window_size] for i in range(0, len(user_messages)-window_size+1, 2)]
        window_scores = [self._calculate_period_score(window) for window in windows]
        
        # æ•´ä½“è¶‹åŠ¿
        if len(window_scores) > 1:
            trend = window_scores[-1] - window_scores[0]
            stability = np.std(window_scores)
        else:
            trend = 0
            stability = 0
        
        # é«˜çº§è¿›åº¦åˆ†æ•°
        progress_score = (
            indicators['done_ratio'] * 0.25 +
            indicators['confidence_ratio'] * 0.2 -
            indicators['stuck_ratio'] * 0.25 -
            indicators['repetition_rate'] * 0.15 +
            trend * 0.15 -
            stability * 0.1  # ç¨³å®šæ€§ä¹Ÿå¾ˆé‡è¦
        )
        
        # é«˜çº§åˆ†ç±»
        if progress_score > 0.4:
            cluster_name = "é«˜çº§è¿›å±•"
            teaching_strategy = "advanced_challenges"
        elif progress_score > 0.1:
            cluster_name = "ç¨³å®šè¿›å±•"
            teaching_strategy = "gradual_advancement"
        elif progress_score > -0.2:
            cluster_name = "éœ€è¦æ”¯æŒ"
            teaching_strategy = "targeted_help"
        else:
            cluster_name = "éœ€è¦å¹²é¢„"
            teaching_strategy = "intensive_support"
        
        return {
            'analysis_type': 'advanced_fallback',
            'cluster_name': cluster_name,
            'progress_score': progress_score,
            'confidence': 0.8,
            'teaching_strategy': teaching_strategy,
            'indicators': indicators,
            'trend': trend,
            'stability': stability,
            'window_scores': window_scores,
            'message_count': len(user_messages),
            'stage': 'advanced'
        }

    def _calculate_detailed_indicators(self, messages: List[str]) -> Dict[str, float]:
        """è®¡ç®—è¯¦ç»†æŒ‡æ ‡"""
        total_msgs = len(messages)
        
        # å…³é”®è¯è®¡æ•°
        done_count = sum(self._count_keywords(msg, self.DONE_KEYWORDS) for msg in messages)
        stuck_count = sum(self._count_keywords(msg, self.STUCK_KEYWORDS) for msg in messages)
        confidence_count = sum(self._count_keywords(msg, self.CONFIDENCE_KEYWORDS) for msg in messages)
        frustration_count = sum(self._count_keywords(msg, self.FRUSTRATION_KEYWORDS) for msg in messages)
        
        # é‡å¤æ€§åˆ†æ
        unique_messages = len(set(msg.lower().strip() for msg in messages))
        repetition_rate = 1.0 - (unique_messages / total_msgs)
        
        # é•¿åº¦å˜åŒ–
        lengths = [len(msg) for msg in messages]
        length_variance = np.var(lengths) if len(lengths) > 1 else 0
        
        # é—®å¥æ¯”ä¾‹
        question_count = sum(1 for msg in messages if '?' in msg)
        question_ratio = question_count / total_msgs
        
        return {
            'done_ratio': done_count / total_msgs,
            'stuck_ratio': stuck_count / total_msgs,
            'confidence_ratio': confidence_count / total_msgs,
            'frustration_ratio': frustration_count / total_msgs,
            'repetition_rate': repetition_rate,
            'question_ratio': question_ratio,
            'length_variance': length_variance,
            'avg_length': np.mean(lengths)
        }

    def _calculate_period_score(self, messages: List[str]) -> float:
        """è®¡ç®—æ—¶æœŸåˆ†æ•°"""
        if not messages:
            return 0.0
        
        indicators = self._calculate_detailed_indicators(messages)
        return (
            indicators['done_ratio'] * 0.4 +
            indicators['confidence_ratio'] * 0.3 -
            indicators['stuck_ratio'] * 0.3 -
            indicators['frustration_ratio'] * 0.2
        )

    def _count_keywords(self, message: str, keywords: set) -> int:
        """è®¡ç®—å…³é”®è¯å‡ºç°æ¬¡æ•°"""
        message_lower = message.lower()
        return sum(1 for keyword in keywords if keyword in message_lower)

    def _get_strategy_from_cluster(self, cluster_name: str) -> str:
        """æ ¹æ®èšç±»åç§°è·å–æ•™å­¦ç­–ç•¥"""
        strategy_map = {
            'ä½è¿›åº¦': 'provide_foundation',
            'æ­£å¸¸': 'maintain_pace',
            'è¶…è¿›åº¦': 'increase_challenge'
        }
        return strategy_map.get(cluster_name, 'adaptive_response')

    def _default_progress_result(self) -> Dict[str, Any]:
        """é»˜è®¤è¿›åº¦ç»“æœ"""
        return {
            'analysis_type': 'insufficient_data',
            'cluster_name': 'æ•°æ®ä¸è¶³',
            'progress_score': 0.0,
            'confidence': 0.0,
            'teaching_strategy': 'collect_more_data',
            'message_count': 0,
            'stage': 'init'
        }


# é›†æˆåˆ°UserStateServiceçš„æ–°æ–¹æ³•
def add_real_time_analysis_to_user_state_service():
    """ä¸ºUserStateServiceæ·»åŠ å®æ—¶åˆ†ææ–¹æ³•"""
    
    def analyze_real_time_progress_enhanced(self, participant_id: str, conversation_history: List[Dict[str, str]]) -> Optional[Dict[str, Any]]:
        """
        å¢å¼ºçš„å®æ—¶è¿›åº¦åˆ†æï¼ˆæ›¿ä»£åŸæœ‰çš„analyze_learning_progressï¼‰
        """
        analyzer = RealTimeProgressAnalyzer()
        result = analyzer.analyze_real_time_progress(participant_id, conversation_history)
        
        if result['analysis_type'] != 'insufficient_data':
            # æ›´æ–°ç”¨æˆ·æ¡£æ¡ˆ
            try:
                profile, _ = self.get_or_create_profile(participant_id, None)
                current_time = datetime.now(UTC)
                
                clustering_data = {
                    'current_cluster': result['cluster_name'],
                    'cluster_confidence': result['confidence'],
                    'progress_score': result['progress_score'],
                    'last_analysis_timestamp': current_time.isoformat(),
                    'conversation_count_analyzed': result['message_count'],
                    'analysis_type': result['analysis_type'],
                    'teaching_strategy': result['teaching_strategy'],
                    'clustering_history': profile.behavior_patterns.get('progress_clustering', {}).get('clustering_history', [])
                }
                
                # æ·»åŠ å†å²è®°å½•
                clustering_data['clustering_history'].append({
                    'timestamp': current_time.isoformat(),
                    'cluster_name': result['cluster_name'],
                    'confidence': result['confidence'],
                    'progress_score': result['progress_score'],
                    'message_count': result['message_count'],
                    'analysis_type': result['analysis_type']
                })
                
                # ä¿æŒå†å²è®°å½•æ•°é‡é™åˆ¶
                if len(clustering_data['clustering_history']) > 20:
                    clustering_data['clustering_history'] = clustering_data['clustering_history'][-20:]
                
                # æ›´æ–°Redis
                set_dict = {
                    'behavior_patterns.progress_clustering': clustering_data
                }
                self.set_profile(profile, set_dict)
                
                logger.info(f"å®æ—¶è¿›åº¦åˆ†æå®Œæˆ: {participant_id} -> {result['cluster_name']} (ç½®ä¿¡åº¦: {result['confidence']:.3f})")
                
            except Exception as e:
                logger.error(f"æ›´æ–°ç”¨æˆ·æ¡£æ¡ˆæ—¶å‡ºé”™: {e}")
        
        return result
    
    # æ·»åŠ æ–¹æ³•åˆ°UserStateServiceç±»
    UserStateService.analyze_real_time_progress_enhanced = analyze_real_time_progress_enhanced


if __name__ == "__main__":
    # æµ‹è¯•å®æ—¶åˆ†æå™¨
    analyzer = RealTimeProgressAnalyzer()
    
    # æµ‹è¯•ä¸åŒé˜¶æ®µ
    test_cases = [
        # æ—©æœŸé˜¶æ®µ
        [{"role": "user", "content": "I don't understand this"}],
        [{"role": "user", "content": "I don't understand this"}, 
         {"role": "user", "content": "Can you help me?"}],
        
        # ä¸­æœŸé˜¶æ®µ
        [{"role": "user", "content": f"Message {i}"} for i in range(7)],
        
        # å®Œæ•´é˜¶æ®µ
        [{"role": "user", "content": f"I'm struggling with problem {i}"} for i in range(15)]
    ]
    
    for i, conversation in enumerate(test_cases):
        print(f"\n{'='*50}")
        print(f"æµ‹è¯•ç”¨ä¾‹ {i+1}: {len(conversation)}æ¡æ¶ˆæ¯")
        result = analyzer.analyze_real_time_progress(f"test_user_{i}", conversation)
        print(f"åˆ†æç»“æœ: {result['cluster_name']}")
        print(f"è¿›åº¦åˆ†æ•°: {result['progress_score']:.3f}")
        print(f"ç½®ä¿¡åº¦: {result['confidence']:.3f}")
        print(f"æ•™å­¦ç­–ç•¥: {result['teaching_strategy']}")
        print(f"åˆ†æç±»å‹: {result['analysis_type']}")





